server:
  port: 8088
  contextPath: /
#  servlet:
#    context-path: /

spring:
  servlet:
    multipart.maxFileSize : 10240KB
    multipart.maxRequestSize: 102400KB
  redis:
    # Redis服务器连接端口
    port: 6379
    # Redis服务器地址
    host: 192.168.12.59
    # Redis数据库索引（默认为0）
    database: 0
    # Redis服务器连接密码（默认为空）
    password: Intellifusion@20190108
    # 连接池最大连接数（使用负值表示没有限制）
    jedis.pool.max-active: 8
    # 连接池最大阻塞等待时间（使用负值表示没有限制）
    jedis.pool.max-wait: -1ms
    # 连接池中的最大空闲连接
    jedis.pool.max-idle: 8
    # 连接池中的最小空闲连接
    jedis.pool.min-idle: 0
    # 连接超时时间（毫秒）
    timeout: 5000ms
  kafka:
    bootstrap-servers: 192.168.12.59:9092  # kafka服务地址:1:端口,kafka服务地址2:端口,kafka服务地址3:端口
    producer:
      # 写入失败时，重试次数。当leader节点失效，一个repli节点会替代成为leader节点，此时可能出现写入失败，
      # 当retris为0时，produce不会重复。retirs重发，此时repli节点完全成为leader节点，不会产生消息丢失。
      retries: 0
      #procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：
      #acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
      #acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应，在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
      #acks = all 这意味着leader将等待完整的同步副本集以确认记录，这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证，这相当于acks = -1的设置。
      #可以设置的值为：all, -1, 0, 1
#      acks: 1
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    consumer:
      group-id: spring-boot-group
      # smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
      auto-offset-reset: earliest
      # 设置自动提交offset
      enable-auto-commit: false
      auto-commit-interval: 100
#      max-poll-records: 2
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  datasource:
#    username: root
#    password: introcks1234
#    url: jdbc:mysql://192.168.13.77:32000/moe?useUnicode=true&characterEncoding=utf8&useSSL=false
#    driver-class-name: com.mysql.jdbc.Driver
#   多数据源
    dynamic:
      primary: master #设置默认的数据源或者数据源组,默认值即为master
      strict: false #严格匹配数据源,默认false. true未匹配到指定数据源时抛异常,false使用默认数据源
      datasource:
        master:
            username: root
            password: 123456
            url: jdbc:mysql://127.0.0.1:3306/moe?useUnicode=true&characterEncoding=utf8&useSSL=false
#            driver-class-name: com.mysql.cj.jdbc.Driver
        test:
            username: root
            password: 123456
            url: jdbc:mysql://127.0.0.1:3306/moe?useUnicode=true&characterEncoding=utf8&useSSL=false
#            driver-class-name: com.mysql.cj.jdbc.Driver
  mail:
    # 163 邮箱
#    host: smtp.163.com
#    port:
    # qq 邮箱
    host: smtp.qq.com
    port: 587
    username: 2245594396@qq.com
    password: jcltmskimiggecja
    protocol: smtp
    default-encoding: UTF-8
    properties:
      mail.smtp.auth: true
      mail.smtp.starttls.enable: true
      mail.smtp.starttls.required: true
      mail.smtp.socketFactory.port: 465
      mail.smtp.socketFactory.class: javax.net.ssl.SSLSocketFactory
      mail.smtp.socketFactory.fallback: false

  flyway:
    #当SpringBoot启动时，这些文件会自动运行。以V开头的文件只会被使用一次，以R开头的文件，在内容发生变化后，再次启动SpringBoot就会被再次执行。
    # 在没有元数据表的情况下，针对非空Schema执行迁移时是否自动调用基线。 （默认值：false）
    baseline-on-migrate: true
    # 下面几个配置不写也行，都是默认配置，这里写了是方便以后改
    # 执行基线时用来标记已有Schema的版本。（默认值：1）
    baseline-version: 1
    enabled: true    #启用flyway
    encoding: utf-8   #字符编码
    migration-prefix: V
    locations: [ "classpath:db/migration" ]  #版本控制文件存放目录

mybatis-plus:
  mapper-locations: classpath:mybatis/mapper/*.xml
#  config-location: classpath:mybatis/mybatis.cfg.xml
  type-aliases-package: com.gumo.demo.entity
#showSql
logging:
  level:
    com:
      example:
        mapper : debug

# dev环境下启用Swagger文档
springfox:
  documentation:
    enabled: true

# rabbitmq 配置
rabbitmq:
  mqtt:
    url: tcp://localhost:1883
    username: guest
    password: guest
    defaultTopic: testTopic

# 分布式文件系统fastdfs配置
fdfs:
  # socket连接超时时长
  soTimeout: 2500
  # 连接tracker服务器超时时长
  connectTimeout: 5000
  pool:
    # 从池中借出的对象的最大数目
    max-total: 153
    # 获取连接时的最大等待毫秒数100
    max-wait-millis: 102
  # 缩略图生成参数，可选
  thumbImage:
    width: 150
    height: 150
  # 跟踪服务器tracker_server请求地址,支持多个，这里只有一个，如果有多个在下方加- x.x.x.x:port
  trackerList:
    - 192.168.11.103:22122

xxl:
  job:
    admin:
      # 调度中心部署跟地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。
      # 执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；
#       addresses: http://127.0.0.1:8080/xxl-job-admin
      addresses:
    # 执行器通讯TOKEN [选填]：非空时启用；
    accessToken: default_token
    executor:
      # 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册
      appname: xxl-job-executor-mileage
      # 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。
      #从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。
      address:
      # 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；
      # 地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；
      ip:
      # 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；
      port: 8888
      # 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；
      logpath: /data/applogs/xxl-job/jobhandler
      # 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；
      logretentiondays: 30
